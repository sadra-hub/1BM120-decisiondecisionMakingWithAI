{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd19ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cell 0] Device in use: cuda\n",
      "[Cell 0] Loading datasets…\n",
      "[Cell 0] Train set size: 136, Test set size: 34\n"
     ]
    }
   ],
   "source": [
    "# Cell 0: Imports, constants, helper functions, CNN class, and data loading\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "from support import load_dataset\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# -----------------------------\n",
    "#        INPUT PARAMETERS\n",
    "# -----------------------------\n",
    "# Choose one of: \"random\" or \"TPE\"\n",
    "SEARCH_METHOD = \"TPE\"    # ← change to \"TPE\" if you want TPE Search\n",
    "\n",
    "# Random seed\n",
    "SEED = 18\n",
    "\n",
    "# Cross-Validation (CV) settings\n",
    "CV_FOLDS  = 5\n",
    "CV_EPOCHS = 40\n",
    "\n",
    "# Optuna hyperparameter tuning settings\n",
    "OPTUNA_TRIALS = 50\n",
    "\n",
    "# Persistent storage URL (one file per method)\n",
    "STORAGE_URL = f\"sqlite:///{SEARCH_METHOD}_hparam_results.db\"\n",
    "\n",
    "# Final model training settings\n",
    "NUM_EPOCHS_FINAL = 40\n",
    "\n",
    "# Hyperparameter search ranges (you can adjust these if desired)\n",
    "HP_LR_LOW    = 1e-5\n",
    "HP_LR_HIGH   = 1e-2\n",
    "HP_DROPOUT_LOW  = 0.1\n",
    "HP_DROPOUT_HIGH = 0.7\n",
    "HP_BATCH_OPTIONS   = [16, 32]\n",
    "HP_NUM_FILTERS_OPTS = [16, 32, 48, 64]\n",
    "\n",
    "# Filenames for saved plots and model checkpoints\n",
    "VAL_CURVES_FILENAME      = \"validation_curves.png\"\n",
    "VAL_LOSS_CURVES_FILENAME = \"validation_loss_curves.png\"\n",
    "# When saving the final retrained model:\n",
    "MODEL_FILENAME = f\"cnn_{SEARCH_METHOD}_best.pth\"\n",
    "\n",
    "# Base directory for plots (one per SEARCH_METHOD)\n",
    "PLOTS_DIR = f\"plots/{SEARCH_METHOD}\"\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "# Other constants\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -----------------------------\n",
    "#        END PARAMETERS\n",
    "# -----------------------------\n",
    "\n",
    "# Set seed for reproducibility\n",
    "def set_seed(seed: int = SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()\n",
    "\n",
    "print(f\"[Cell 0] Device in use: {DEVICE}\")\n",
    "print(\"[Cell 0] Loading datasets…\")\n",
    "train_dataset, test_dataset = load_dataset()\n",
    "print(f\"[Cell 0] Train set size: {len(train_dataset)}, Test set size: {len(test_dataset)}\")\n",
    "\n",
    "# Define CNN (single definition)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_filters: int = 16, dropout: float = 0.5):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, num_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(num_filters, num_filters * 2, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        # Dynamically compute flattened size (input assumed 60 × 30)\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 3, 60, 30)\n",
    "            out = self.features(dummy)\n",
    "            flat_size = out.view(1, -1).shape[1]\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flat_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Training / evaluation helpers\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc  = correct / len(loader.dataset)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "def evaluate_loss(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            count += inputs.size(0)\n",
    "    return total_loss / count\n",
    "\n",
    "# Train a model for multiple epochs (used later for final retraining)\n",
    "def train_full_model(model, train_loader, test_loader, criterion, optimizer, device, num_epochs: int):\n",
    "    train_accs = []\n",
    "    train_losses = []\n",
    "    test_accs = []\n",
    "    test_losses = []\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Train on training set\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc  = correct / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluate on test set\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        count = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                count += inputs.size(0)\n",
    "        test_loss = total_loss / count\n",
    "        test_acc  = correct / count\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "\n",
    "        print(\n",
    "            f\"[Final] Epoch {epoch:02d}/{num_epochs} | \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "            f\"Test  Loss: {test_loss:.4f}, Test  Acc: {test_acc:.4f}\"\n",
    "        )\n",
    "    return train_losses, train_accs, test_losses, test_accs\n",
    "\n",
    "# Plot learning curves (accuracy + loss) and save under plots/{SEARCH_METHOD}/…\n",
    "def plot_learning_curves(\n",
    "    epochs,\n",
    "    train_accs,\n",
    "    test_accs,\n",
    "    train_losses,\n",
    "    test_losses,\n",
    "    acc_title: str,\n",
    "    loss_title: str,\n",
    "    acc_filepath: str,\n",
    "    loss_filepath: str\n",
    "):\n",
    "    # Accuracy plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, train_accs, marker='o', label=\"Train Accuracy\")\n",
    "    plt.plot(epochs, test_accs, marker='s', label=\"Test Accuracy\")\n",
    "    if train_accs:\n",
    "        best_train_idx = int(np.argmax(train_accs))\n",
    "        best_train_val = max(train_accs)\n",
    "        plt.scatter(epochs[best_train_idx], best_train_val, color='blue')\n",
    "        plt.text(epochs[best_train_idx], best_train_val + 0.01,\n",
    "                 f\"Max Train Acc: {best_train_val:.2f}\", color='blue')\n",
    "    if test_accs:\n",
    "        best_test_idx = int(np.argmax(test_accs))\n",
    "        best_test_val = max(test_accs)\n",
    "        plt.scatter(epochs[best_test_idx], best_test_val, color='orange')\n",
    "        plt.text(epochs[best_test_idx], best_test_val + 0.01,\n",
    "                 f\"Max Test Acc: {best_test_val:.2f}\", color='orange')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(acc_title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(acc_filepath, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # Loss plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, train_losses, marker='o', label=\"Train Loss\")\n",
    "    plt.plot(epochs, test_losses, marker='s', label=\"Test Loss\")\n",
    "    if train_losses:\n",
    "        best_train_loss_idx = int(np.argmin(train_losses))\n",
    "        best_train_loss_val = min(train_losses)\n",
    "        plt.scatter(epochs[best_train_loss_idx], best_train_loss_val, color='blue')\n",
    "        plt.text(epochs[best_train_loss_idx], best_train_loss_val + 0.01,\n",
    "                 f\"Min Train Loss: {best_train_loss_val:.2f}\", color='blue')\n",
    "    if test_losses:\n",
    "        best_test_loss_idx = int(np.argmin(test_losses))\n",
    "        best_test_loss_val = min(test_losses)\n",
    "        plt.scatter(epochs[best_test_loss_idx], best_test_loss_val, color='orange')\n",
    "        plt.text(epochs[best_test_loss_idx], best_test_loss_val + 0.01,\n",
    "                 f\"Min Test Loss: {best_test_loss_val:.2f}\", color='orange')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(loss_title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(loss_filepath, dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Run a single hyperparameter search (“random” or “TPE”) and save trials to SQLite\n",
    "\n",
    "print(f\"[Cell 1] Starting {SEARCH_METHOD.upper()} Search hyperparameter tuning…\")\n",
    "\n",
    "# Precompute labels and indices for StratifiedKFold\n",
    "labels_list = [int(train_dataset[i][1]) for i in range(len(train_dataset))]\n",
    "all_indices = list(range(len(train_dataset)))\n",
    "\n",
    "def objective(trial):\n",
    "    # Sample hyperparameters within the ranges defined in Cell 0\n",
    "    lr            = trial.suggest_float(\"lr\", HP_LR_LOW, HP_LR_HIGH, log=True)\n",
    "    dropout       = trial.suggest_float(\"dropout\", HP_DROPOUT_LOW, HP_DROPOUT_HIGH)\n",
    "    optimizer_name= trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"])\n",
    "    batch_size    = trial.suggest_categorical(\"batch_size\", HP_BATCH_OPTIONS)\n",
    "    num_filters   = trial.suggest_categorical(\"num_filters\", HP_NUM_FILTERS_OPTS)\n",
    "\n",
    "    print(\n",
    "        f\"[Trial {trial.number}] lr={lr:.2e}, dropout={dropout:.2f}, \"\n",
    "        f\"opt={optimizer_name}, batch_size={batch_size}, num_filters={num_filters}\"\n",
    "    )\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=SEED)\n",
    "    fold_accuracies = []\n",
    "    fold_losses     = []\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(all_indices, labels_list), start=1):\n",
    "        train_sub = Subset(train_dataset, train_idx)\n",
    "        val_sub   = Subset(train_dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_sub,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_sub,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "        model     = CNN(num_filters=num_filters, dropout=dropout).to(DEVICE)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = (\n",
    "            optim.Adam(model.parameters(), lr=lr)\n",
    "            if optimizer_name == \"Adam\"\n",
    "            else optim.SGD(model.parameters(), lr=lr)\n",
    "        )\n",
    "\n",
    "        # Train for CV_EPOCHS on this fold\n",
    "        for epoch in range(1, CV_EPOCHS + 1):\n",
    "            train_one_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "            if epoch == CV_EPOCHS or epoch % 5 == 0:\n",
    "                print(f\"    [Fold {fold_idx}] Epoch {epoch}/{CV_EPOCHS}\")\n",
    "\n",
    "        # Evaluate on validation fold\n",
    "        total_loss = 0.0\n",
    "        correct    = 0\n",
    "        total      = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += inputs.size(0)\n",
    "\n",
    "        mean_loss_fold = total_loss / total\n",
    "        acc_fold       = correct / total\n",
    "\n",
    "        print(\n",
    "            f\"    → Fold {fold_idx} results: Acc={acc_fold:.4f}, Loss={mean_loss_fold:.4f}\"\n",
    "        )\n",
    "        fold_losses.append(mean_loss_fold)\n",
    "        fold_accuracies.append(acc_fold)\n",
    "\n",
    "    mean_cv_acc  = float(np.mean(fold_accuracies))\n",
    "    mean_cv_loss = float(np.mean(fold_losses))\n",
    "    trial.set_user_attr(\"mean_cv_loss\", mean_cv_loss)\n",
    "\n",
    "    print(\n",
    "        f\"[Trial {trial.number}] mean CV Acc={mean_cv_acc:.4f}, mean CV Loss={mean_cv_loss:.4f}\\n\"\n",
    "    )\n",
    "    return mean_cv_acc\n",
    "\n",
    "# Choose sampler based on SEARCH_METHOD\n",
    "if SEARCH_METHOD.lower() == \"random\":\n",
    "    sampler    = optuna.samplers.RandomSampler()\n",
    "    study_name = \"random_search\"\n",
    "elif SEARCH_METHOD.lower() == \"tpe\":\n",
    "    sampler    = optuna.samplers.TPESampler()\n",
    "    study_name = \"tpe_search\"\n",
    "else:\n",
    "    raise ValueError(\"SEARCH_METHOD must be either 'random' or 'TPE'\")\n",
    "\n",
    "# Create or load study\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=STORAGE_URL,\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    "    sampler=sampler\n",
    ")\n",
    "study.optimize(objective, n_trials=OPTUNA_TRIALS)\n",
    "\n",
    "best_trial   = study.best_trial\n",
    "best_params  = best_trial.params\n",
    "best_cv_acc  = best_trial.value\n",
    "best_cv_loss = best_trial.user_attrs.get(\"mean_cv_loss\", float(\"nan\"))\n",
    "\n",
    "print(\n",
    "    f\"[Cell 1] {SEARCH_METHOD.upper()} Search best trial #{best_trial.number} | \"\n",
    "    f\"Hyperparams={best_params} | CV Acc={best_cv_acc:.4f} | CV Loss={best_cv_loss:.4f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa128565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Plot validation curves & retrain the best‐so‐far model on full data\n",
    "\n",
    "# 1) Create plots/{SEARCH_METHOD} directory if it doesn’t exist (in case Cell 0 wasn’t re‐run)\n",
    "os.makedirs(f\"plots/{SEARCH_METHOD}\", exist_ok=True)\n",
    "\n",
    "print(\"[Cell 2] Loading the saved study from disk…\")\n",
    "study_name = f\"{SEARCH_METHOD.lower()}_search\"\n",
    "study = optuna.load_study(\n",
    "    study_name=study_name,\n",
    "    storage=STORAGE_URL\n",
    ")\n",
    "\n",
    "# 2a) Print all trials with their hyperparameters, CV accuracy & CV loss\n",
    "print(f\"\\n{SEARCH_METHOD.upper()} Search trial summary:\")\n",
    "for t in study.trials:\n",
    "    params = t.params\n",
    "    acc    = t.value if t.value is not None else \"N/A\"\n",
    "    loss   = t.user_attrs.get(\"mean_cv_loss\", \"N/A\")\n",
    "    print(f\"  Trial #{t.number:2d} | Params={params} | CV Acc={acc} | CV Loss={loss}\")\n",
    "\n",
    "# 2b) Extract only the completed trials (i.e. t.value is not None)\n",
    "valid_trials   = [t for t in study.trials if t.value is not None]\n",
    "trial_nums     = [t.number for t in valid_trials]\n",
    "trial_accs     = [t.value  for t in valid_trials]\n",
    "trial_losses   = [t.user_attrs.get(\"mean_cv_loss\", np.nan) for t in valid_trials]\n",
    "\n",
    "# 2c) Scatter-plots: each hyperparameter versus CV accuracy\n",
    "print(f\"\\n[Cell 2] Plotting scatter‐plots of {SEARCH_METHOD.upper()} hyperparameters vs. CV accuracy…\")\n",
    "param_names = list(study.best_params.keys())\n",
    "for param in param_names:\n",
    "    x_vals = [t.params[param] for t in valid_trials]\n",
    "    y_vals = [t.value           for t in valid_trials]\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(x_vals, y_vals, marker='o', edgecolor='k')\n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel(\"Mean CV Accuracy\")\n",
    "    plt.title(f\"{SEARCH_METHOD.capitalize()} Search: {param} vs. CV Accuracy\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{PLOTS_DIR}/scatter_{SEARCH_METHOD.lower()}_{param}.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# 2d) Plot validation-accuracy curve (CV accuracy vs. trial number)\n",
    "print(\"\\n[Cell 2] Plotting validation accuracy curve…\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(trial_nums, trial_accs, marker='o', label=f\"{SEARCH_METHOD.capitalize()} CV Acc\")\n",
    "if trial_accs:\n",
    "    best_idx = trial_nums[np.argmax(trial_accs)]\n",
    "    best_val = max(trial_accs)\n",
    "    plt.scatter(best_idx, best_val, color='blue')\n",
    "    plt.text(best_idx, best_val + 0.005, f\"Max CV Acc: {best_val:.2f}\", color='blue')\n",
    "plt.xlabel(\"Trial Number\")\n",
    "plt.ylabel(\"Mean CV Accuracy\")\n",
    "plt.title(f\"{SEARCH_METHOD.capitalize()} Search: Validation Accuracy ({CV_FOLDS}-Fold, {CV_EPOCHS} Epochs)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{PLOTS_DIR}/{VAL_CURVES_FILENAME}\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 2e) Plot validation-loss curve (CV loss vs. trial number)\n",
    "print(\"\\n[Cell 2] Plotting validation loss curve…\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(trial_nums, trial_losses, marker='s', label=f\"{SEARCH_METHOD.capitalize()} CV Loss\")\n",
    "if trial_losses:\n",
    "    best_loss_idx = trial_nums[np.nanargmin(trial_losses)]\n",
    "    best_loss_val = min([v for v in trial_losses if not np.isnan(v)])\n",
    "    plt.scatter(best_loss_idx, best_loss_val, color='orange')\n",
    "    plt.text(best_loss_idx, best_loss_val + 0.005, f\"Min CV Loss: {best_loss_val:.2f}\", color='orange')\n",
    "plt.xlabel(\"Trial Number\")\n",
    "plt.ylabel(\"Mean CV Loss\")\n",
    "plt.title(f\"{SEARCH_METHOD.capitalize()} Search: Validation Loss ({CV_FOLDS}-Fold, {CV_EPOCHS} Epochs)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{PLOTS_DIR}/{VAL_LOSS_CURVES_FILENAME}\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 3) Retrain the best-so-far trial on the full training set and plot its learning curves\n",
    "criterion_final = nn.CrossEntropyLoss()\n",
    "\n",
    "def build_model_and_optimizer(params):\n",
    "    model = CNN(num_filters=params[\"num_filters\"], dropout=params[\"dropout\"]).to(DEVICE)\n",
    "    optimizer = (\n",
    "        optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "        if params[\"optimizer\"] == \"Adam\"\n",
    "        else optim.SGD(model.parameters(), lr=params[\"lr\"])\n",
    "    )\n",
    "    return model, optimizer\n",
    "\n",
    "best_trial   = study.best_trial\n",
    "best_params  = best_trial.params\n",
    "best_cv_acc  = best_trial.value\n",
    "best_cv_loss = best_trial.user_attrs.get(\"mean_cv_loss\", float(\"nan\"))\n",
    "\n",
    "print(\n",
    "    f\"\\n[Cell 2] Best‐so‐far {SEARCH_METHOD.upper()} trial #{best_trial.number} | \"\n",
    "    f\"Hyperparams={best_params} | CV Acc={best_cv_acc:.4f} | CV Loss={best_cv_loss:.4f}\"\n",
    ")\n",
    "\n",
    "model_best, opt_best = build_model_and_optimizer(best_params)\n",
    "train_loader_best = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=best_params[\"batch_size\"],  # use tuned batch_size\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=best_params[\"batch_size\"],  # also use tuned batch_size on test if desired\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"[Cell 2] Training {SEARCH_METHOD.capitalize()}-best model on full training set…\")\n",
    "best_train_losses, best_train_accs, best_test_losses, best_test_accs = train_full_model(\n",
    "    model_best,\n",
    "    train_loader_best,\n",
    "    test_loader,\n",
    "    criterion_final,\n",
    "    opt_best,\n",
    "    DEVICE,\n",
    "    NUM_EPOCHS_FINAL\n",
    ")\n",
    "\n",
    "epochs_final = np.arange(1, NUM_EPOCHS_FINAL + 1)\n",
    "print(\"[Cell 2] Plotting learning curves for the best-so-far model…\")\n",
    "plot_learning_curves(\n",
    "    epochs_final,\n",
    "    best_train_accs,\n",
    "    best_test_accs,\n",
    "    best_train_losses,\n",
    "    best_test_losses,\n",
    "    acc_title=f\"{SEARCH_METHOD.capitalize()} Best Model: Train & Test Accuracy per Epoch\",\n",
    "    loss_title=f\"{SEARCH_METHOD.capitalize()} Best Model: Train & Test Loss per Epoch\",\n",
    "    acc_filepath=f\"{PLOTS_DIR}/best_{SEARCH_METHOD.lower()}_learning_curve.png\",\n",
    "    loss_filepath=f\"{PLOTS_DIR}/best_{SEARCH_METHOD.lower()}_loss_curve.png\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
