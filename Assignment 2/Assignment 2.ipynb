{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86634eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-06-03 19:59:35,664] Trial 7 failed with parameters: {'lr': 0.061287781262444135, 'wd': 0.0520152161762041, 'pool': 0, 'bs': 256, 'ep': 5} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\flori\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_18224\\3413818634.py\", line 190, in objective\n",
      "    cv_loss, tr_curve, vl_curve, fold_vals = cross_validate(\n",
      "                                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_18224\\3413818634.py\", line 120, in cross_validate\n",
      "    for xb, yb in tr_loader:\n",
      "                  ^^^^^^^^^\n",
      "  File \"C:\\Users\\flori\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py\", line 733, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\flori\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1479, in _next_data\n",
      "    self._shutdown_workers()\n",
      "  File \"C:\\Users\\flori\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1627, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\multiprocessing\\process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\multiprocessing\\popen_spawn_win32.py\", line 112, in wait\n",
      "    res = _winapi.WaitForSingleObject(int(self._handle), msecs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-06-03 19:59:35,893] Trial 7 failed with value None.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import optuna\n",
    "from optuna.importance import get_param_importances\n",
    "from optuna.visualization.matplotlib import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    ")\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "# -------------- 0. housekeeping  --------------------------------\n",
    "k_folds    = 5\n",
    "max_trials = 1000                    # try up to 1000 trials, but we can interrupt early\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "\n",
    "# Redirect stdout to both console + log file\n",
    "class Tee:\n",
    "    def __init__(self, *streams):\n",
    "        self.streams = streams\n",
    "    def write(self, data):\n",
    "        for s in self.streams:\n",
    "            s.write(data)\n",
    "            s.flush()\n",
    "    def flush(self):\n",
    "        for s in self.streams:\n",
    "            s.flush()\n",
    "\n",
    "log_file = open(\"output.txt\", \"w\")\n",
    "sys.stdout = Tee(sys.__stdout__, log_file)\n",
    "\n",
    "print(f\"Settings  |  k_folds = {k_folds},  max_trials = {max_trials}\\n\")\n",
    "\n",
    "# -------------- 1. load data -----------------------------------\n",
    "sys.path.append(\n",
    "    r\"C:\\Users\\flori\\OneDrive - TU Eindhoven\\Master TUe 2024-2025\\1BM120 - Decision Making with Artificial Intelligence\\Assignment 2\"\n",
    ")\n",
    "from support import load_dataset\n",
    "\n",
    "trainset, testset = load_dataset()\n",
    "num_classes = len(trainset.classes)\n",
    "print(f\"Loaded  |  train = {len(trainset)},  test = {len(testset)}\")\n",
    "print(\"Classes :\", trainset.classes, \"\\n\")\n",
    "\n",
    "# -------------- 2. define CNN ----------------------------------\n",
    "class CNN_CV(nn.Module):\n",
    "    def __init__(self, n_cls, pooltype=0):\n",
    "        super().__init__()\n",
    "        self.conv1  = nn.Conv2d(3, 16, 3, stride=1, padding=1)\n",
    "        self.relu1  = nn.ReLU()\n",
    "        if pooltype == 0:\n",
    "            self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        else:\n",
    "            self.pool1 = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        self.conv2  = nn.Conv2d(16, 16, 3, stride=1, padding=1)\n",
    "        self.relu2  = nn.ReLU()\n",
    "        if pooltype == 0:\n",
    "            self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        else:\n",
    "            self.pool2 = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        # After two 2×2 pools: 60×30 → 30×15 → 15×7, channels=16\n",
    "        self.fc1     = nn.Linear(16 * 15 * 7, n_cls)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc1(x)    # raw logits\n",
    "\n",
    "# -------------- 3. CV + pruning routine ------------------------\n",
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def cross_validate(lr, wd, pooltype, bs, epochs, trial_id, trial=None):\n",
    "    \"\"\"\n",
    "    Runs k-fold CV, reporting intermediate val‐loss for pruning.\n",
    "    Returns: mean CV loss, avg_train_curve, avg_val_curve, fold_val_losses.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    fold_val_losses  = []\n",
    "    fold_train_epoch = []\n",
    "    fold_val_epoch   = []\n",
    "\n",
    "    splits = list(kf.split(trainset))\n",
    "    for fold, (tr_idx, val_idx) in enumerate(splits, start=1):\n",
    "        print(f\"-- Fold {fold}/{k_folds}  (trial {trial_id})  |  lr={lr:.1e}, wd={wd:.1e}, pool={'max' if pooltype==0 else 'avg'}, bs={bs}, ep={epochs}\")\n",
    "\n",
    "        trainset_CV = Subset(trainset, tr_idx)\n",
    "        valset_CV   = Subset(trainset, val_idx)\n",
    "        tr_loader   = DataLoader(trainset_CV, batch_size=bs, shuffle=True,  pin_memory=True, num_workers=4)\n",
    "        vl_loader   = DataLoader(valset_CV,   batch_size=bs, shuffle=False, pin_memory=True, num_workers=4)\n",
    "\n",
    "        model_CV = CNN_CV(num_classes, pooltype).to(device)\n",
    "        optimizer = optim.Adam(model_CV.parameters(), lr=lr, weight_decay=wd)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        tr_curve = []\n",
    "        vl_curve = []\n",
    "\n",
    "        for ep in range(1, epochs + 1):\n",
    "            # ---------- TRAIN ----------\n",
    "            model_CV.train()\n",
    "            running_loss, correct = 0.0, 0\n",
    "            for xb, yb in tr_loader:\n",
    "                xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model_CV(xb)\n",
    "                loss   = criterion(logits, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                preds = logits.argmax(dim=1)\n",
    "                correct += (preds == yb).sum().item()\n",
    "\n",
    "            tr_loss = running_loss / len(tr_loader)\n",
    "            tr_acc  = 100.0 * correct / len(trainset_CV)\n",
    "            tr_curve.append(tr_loss)\n",
    "\n",
    "            # ---------- VALIDATION ----------\n",
    "            model_CV.eval()\n",
    "            vloss_sum, vcorrect = 0.0, 0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in vl_loader:\n",
    "                    xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "                    logits = model_CV(xb)\n",
    "                    loss   = criterion(logits, yb)\n",
    "                    vloss_sum += loss.item()\n",
    "                    preds = logits.argmax(dim=1)\n",
    "                    vcorrect += (preds == yb).sum().item()\n",
    "\n",
    "            v_loss = vloss_sum / len(vl_loader)\n",
    "            v_acc  = 100.0 * vcorrect / len(valset_CV)\n",
    "            vl_curve.append(v_loss)\n",
    "\n",
    "            # Print & update TQDM\n",
    "            print(f\"   Epoch {ep:02d}/{epochs}  |  train_loss={tr_loss:.4f} ({tr_acc:.1f}%)  val_loss={v_loss:.4f} ({v_acc:.1f}%)\")\n",
    "\n",
    "            # -------- PRUNE CHECK --------\n",
    "            if trial is not None:\n",
    "                step = (fold - 1) * epochs + ep\n",
    "                trial.report(v_loss, step=step)\n",
    "                if trial.should_prune():\n",
    "                    print(f\"   >>> Trial {trial.number+1} pruned at fold {fold}, epoch {ep} (val_loss={v_loss:.4f})\")\n",
    "                    raise optuna.TrialPruned()\n",
    "\n",
    "        fold_train_epoch.append(tr_curve)\n",
    "        fold_val_epoch.append(vl_curve)\n",
    "        fold_val_losses.append(vl_curve[-1])\n",
    "        print(f\"   Fold done | final val loss = {vl_curve[-1]:.4f}\\n\")\n",
    "\n",
    "    mean_cv = float(np.mean(fold_val_losses))\n",
    "    print(f\"*** Mean CV loss = {mean_cv:.4f} ***\\n\")\n",
    "\n",
    "    avg_tr = np.mean(fold_train_epoch, axis=0)\n",
    "    avg_vl = np.mean(fold_val_epoch, axis=0)\n",
    "    return mean_cv, avg_tr, avg_vl, fold_val_losses\n",
    "\n",
    "# -------------- 4. objective + callback -----------------------\n",
    "history = {k: [] for k in (\"lr\",\"wd\",\"pool\",\"bs\",\"ep\",\"cv_loss\",\"train_curve\",\"val_curve\",\"fold_val_losses\")}\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # 4 hyperparameters to tune\n",
    "    lr        = trial.suggest_float(\"lr\", 1e-8, 1e-1, log=True)\n",
    "    wd        = trial.suggest_float(\"wd\", 1e-8, 1e-1, log=True)\n",
    "    pooltype  = trial.suggest_categorical(\"pool\", [0, 1])\n",
    "    bs        = trial.suggest_categorical(\"bs\",   [8,16,32,64,128,256])  # batch size\n",
    "    ep        = trial.suggest_categorical(\"ep\", [5,10,15,20,25,30])   # number of epochs\n",
    "    t_id      = trial.number + 1\n",
    "\n",
    "    print(f\"== Trial {t_id}/{max_trials}  |  lr={lr:.1e}, wd={wd:.1e}, pool={pooltype}, bs={bs}, ep={ep}\")\n",
    "\n",
    "    try:\n",
    "        cv_loss, tr_curve, vl_curve, fold_vals = cross_validate(\n",
    "            lr, wd, pooltype, bs, ep, t_id, trial=trial\n",
    "        )\n",
    "    except optuna.TrialPruned:\n",
    "        print(f\"<<< Trial {t_id} pruned >>>\\n\")\n",
    "        raise\n",
    "\n",
    "    # store everything in history\n",
    "    history[\"lr\"].append(lr)\n",
    "    history[\"wd\"].append(wd)\n",
    "    history[\"pool\"].append(pooltype)\n",
    "    history[\"bs\"].append(bs)\n",
    "    history[\"ep\"].append(ep)\n",
    "    history[\"cv_loss\"].append(cv_loss)\n",
    "    history[\"train_curve\"].append(tr_curve)\n",
    "    history[\"val_curve\"].append(vl_curve)\n",
    "    history[\"fold_val_losses\"].append(fold_vals)\n",
    "\n",
    "    # save learning‐curve figure for this specific trial\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(range(1, ep+1), tr_curve, label=\"train\")\n",
    "    ax.plot(range(1, ep+1), vl_curve, label=\"val\")\n",
    "    ax.set_xlabel(\"epoch\"); ax.set_ylabel(\"loss\")\n",
    "    ax.set_title(f\"Learning curve | trial {t_id}\")\n",
    "    ax.legend()\n",
    "    #fig.tight_layout()\n",
    "    fig.savefig(f\"figures/learning_curve_trial_{t_id}.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    return cv_loss\n",
    "\n",
    "def after_trial_callback(study: optuna.Study, trial: optuna.Trial) -> None:\n",
    "    t_id       = trial.number + 1\n",
    "    best_p     = study.best_params\n",
    "    best_val   = study.best_value\n",
    "    print(f\"   --> After Trial {t_id}: Best so far = {best_p} (CV loss = {best_val:.4f})\\n\")\n",
    "\n",
    "    imp = get_param_importances(study)\n",
    "    print(\"   Parameter importances:\")\n",
    "    for nm, val in imp.items():\n",
    "        print(f\"      {nm}: {val:.4f}\")\n",
    "    print(\"\")\n",
    "\n",
    "    fig1 = plot_optimization_history(study)\n",
    "    #fig1.tight_layout()\n",
    "    fig1.savefig(f\"figures/opt_history_after_trial_{t_id}.png\")\n",
    "    plt.close(fig1)\n",
    "\n",
    "    # only compute & plot importances after more than one trial\n",
    "    if len(study.trials) > 1:\n",
    "        imp = get_param_importances(study)\n",
    "        print(\"   Parameter importances:\")\n",
    "        for nm, val in imp.items():\n",
    "            print(f\"      {nm}: {val:.4f}\")\n",
    "        print(\"\")\n",
    "        fig2 = plot_param_importances(study)\n",
    "        #fig2.tight_layout()\n",
    "        fig2.savefig(f\"figures/param_importances_after_trial_{t_id}.png\")\n",
    "        plt.close(fig2)\n",
    "    else:\n",
    "        print(\"   Skipping parameter importances (need >1 trial).\")\n",
    "\n",
    "# -------------- 5. create/load study ----------------------------\n",
    "storage_name = \"sqlite:///optuna_study.db\"\n",
    "study_name   = \"cnn_pruning_study\"\n",
    "\n",
    "# If the DB file already exists, load that study; otherwise create a new one.\n",
    "try:\n",
    "    study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "    print(\"Loaded existing study; continuing from last trial count:\", len(study.trials))\n",
    "except KeyError:\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=storage_name,\n",
    "        direction=\"minimize\",\n",
    "        sampler=optuna.samplers.TPESampler(seed=42),\n",
    "        pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=0),\n",
    "    )\n",
    "    print(\"Created new study:\", study.study_name)\n",
    "\n",
    "# -------------- 6. run optimization (interruptible) -------------\n",
    "search_start = time.perf_counter()\n",
    "try:\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=max_trials,\n",
    "        callbacks=[after_trial_callback],\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"==> Interrupted by user. Trials so far have been saved to disk.\\n\")\n",
    "\n",
    "elapsed = time.perf_counter() - search_start\n",
    "print(f\"\\n### Done (or interrupted) after {elapsed/60:.1f} min. ###\")\n",
    "print(\"Total trials completed:\", len(study.trials))\n",
    "print(\"Best hyper‐params so far:\", study.best_params)\n",
    "print(f\"Best CV loss = {study.best_value:.4f}\")\n",
    "\n",
    "# store history in the study itself so we can retrieve it later\n",
    "study.set_user_attr(\"history\", history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9d29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_12696\\567735747.py:29: ExperimentalWarning: plot_optimization_history is experimental (supported from v2.2.0). The interface can change in the future.\n",
      "  fig = plot_optimization_history(study)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Axes' object has no attribute 'tight_layout'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# -------------- 2. re‐plot overall optimization history -------------\u001b[39;00m\n\u001b[0;32m     29\u001b[0m fig \u001b[38;5;241m=\u001b[39m plot_optimization_history(study)\n\u001b[1;32m---> 30\u001b[0m fig\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m     31\u001b[0m fig\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfigures/opt_history_overall.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Axes' object has no attribute 'tight_layout'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell [ ]: resume_and_plot.py\n",
    "\n",
    "import os, json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from optuna.importance import get_param_importances\n",
    "from optuna.visualization.matplotlib import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    ")\n",
    "\n",
    "# -------------- 1. load study from disk ------------------------\n",
    "storage_name = \"sqlite:///optuna_study.db\"\n",
    "study_name   = \"cnn_pruning_study\"\n",
    "study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "\n",
    "history = study.user_attrs[\"history\"]\n",
    "\n",
    "print(f\"Loaded study '{study_name}' with {len(study.trials)} trials\")\n",
    "print(\"Best params so far:\", study.best_params)\n",
    "print(f\"Best CV loss = {study.best_value:.4f}\")\n",
    "\n",
    "# -------------- 2. re‐plot overall optimization history -------------\n",
    "fig = plot_optimization_history(study)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"figures/opt_history_overall.png\")\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "fig = plot_param_importances(study)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"figures/param_importances_overall.png\")\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "# -------------- 3. define exactly the same CNN class --------------\n",
    "import sys\n",
    "sys.path.append(\n",
    "    r\"C:\\Users\\flori\\OneDrive - TU Eindhoven\\Master TUe 2024-2025\\1BM120 - Decision Making with Artificial Intelligence\\Assignment 2\"\n",
    ")\n",
    "from support import load_dataset\n",
    "\n",
    "trainset, testset = load_dataset()\n",
    "num_classes = len(trainset.classes)\n",
    "\n",
    "class CNN_CV(nn.Module):\n",
    "    def __init__(self, n_cls, pooltype=0):\n",
    "        super().__init__()\n",
    "        self.conv1  = nn.Conv2d(3, 16, 3, stride=1, padding=1)\n",
    "        self.relu1  = nn.ReLU()\n",
    "        if pooltype == 0:\n",
    "            self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        else:\n",
    "            self.pool1 = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        self.conv2  = nn.Conv2d(16, 16, 3, stride=1, padding=1)\n",
    "        self.relu2  = nn.ReLU()\n",
    "        if pooltype == 0:\n",
    "            self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        else:\n",
    "            self.pool2 = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(16 * 15 * 7, n_cls)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc1(x)\n",
    "\n",
    "# -------------- 4. train the best‐so‐far model on full training set ----\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best = study.best_params\n",
    "\n",
    "# unpack best params\n",
    "lr       = best[\"lr\"]\n",
    "wd       = best[\"wd\"]\n",
    "pooltype = best[\"pool\"]\n",
    "bs       = best[\"bs\"]\n",
    "ep       = best[\"ep\"]\n",
    "\n",
    "print(\"Training final model with best‐found hyperparameters:\")\n",
    "print(f\"  lr={lr:.1e}, wd={wd:.1e}, pool={pooltype}, bs={bs}, epochs={ep}\\n\")\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(testset,  batch_size=bs, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "model_final = CNN_CV(num_classes, pooltype).to(device)\n",
    "optimizer_final = optim.Adam(model_final.parameters(), lr=lr, weight_decay=wd)\n",
    "criterion_final = nn.CrossEntropyLoss()\n",
    "\n",
    "# training loop\n",
    "for epoch in range(1, ep + 1):\n",
    "    model_final.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "        optimizer_final.zero_grad()\n",
    "        logits = model_final(xb)\n",
    "        loss = criterion_final(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer_final.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc  = 100.0 * correct / len(trainset)\n",
    "    print(f\"Epoch {epoch:02d}/{ep}  |  Train loss={train_loss:.4f}, Train acc={train_acc:.1f}%\")\n",
    "\n",
    "print(\"\\nFinished training final model.\\n\")\n",
    "\n",
    "# -------------- 5. evaluate on test set ------------------------\n",
    "model_final.eval()\n",
    "all_preds = []\n",
    "all_lbls  = []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        logits = model_final(xb).cpu()\n",
    "        all_preds.append(logits.argmax(dim=1))\n",
    "        all_lbls.append(yb)\n",
    "\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_lbls  = torch.cat(all_lbls).numpy()\n",
    "\n",
    "cm = confusion_matrix(all_lbls, all_preds, labels=list(range(num_classes)))\n",
    "fig_cm, ax_cm = plt.subplots(figsize=(6, 5))\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=trainset.classes)\n",
    "disp.plot(ax=ax_cm, cmap=\"Blues\", colorbar=False)\n",
    "ax_cm.set_title(\"Confusion matrix (test set) — Final model\")\n",
    "fig_cm.tight_layout()\n",
    "fig_cm.savefig(\"figures/confusion_matrix_final.png\")\n",
    "plt.show()\n",
    "plt.close(fig_cm)\n",
    "\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.bar(range(num_classes), per_class_acc)\n",
    "ax.set_xticks(range(num_classes))\n",
    "ax.set_xticklabels(trainset.classes, rotation=45, ha=\"right\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"Per‐class accuracy (test set) — Final model\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"figures/per_class_accuracy_final.png\")\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "# -------------- 6. (Optional) plot validation‐curves for each trial ------------\n",
    "# You can iterate through history if you want more detailed per‐trial analysis,\n",
    "# but generally the above plots suffice.\n",
    "\n",
    "import os\n",
    "\n",
    "# Make sure the directory for per‐trial plots exists\n",
    "os.makedirs(\"figures/validation_curves\", exist_ok=True)\n",
    "\n",
    "for i, (tr_curve, vl_curve) in enumerate(zip(history[\"train_curve\"], history[\"val_curve\"]), start=1):\n",
    "    epochs_i = range(1, len(tr_curve) + 1)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(epochs_i, tr_curve, label=\"train\")\n",
    "    ax.plot(epochs_i, vl_curve, label=\"val\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(f\"Trial {i}  —  Validation Curves\")\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"figures/validation_curves/trial_{i}_val_curve.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "print(\"All diagnostics + final model plots are saved under ./figures\")\n",
    "print(\"Notebook cell complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c8eba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:17:44 | INFO     | Loading datasets …\n",
      "22:17:44 | INFO     | Dataset sizes — train: 136  |  test: 34\n",
      "22:17:44 | INFO     | Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:17:44 | INFO     | [Baseline] ➜ Starting training for 20 epochs\n",
      "22:18:14 | INFO     | [Baseline] Epoch 01/20 — loss: 0.7053  acc: 0.4118\n",
      "22:18:45 | INFO     | [Baseline] Epoch 02/20 — loss: 0.6930  acc: 0.5147\n",
      "22:19:16 | INFO     | [Baseline] Epoch 03/20 — loss: 0.6910  acc: 0.5441\n",
      "22:19:44 | INFO     | [Baseline] Epoch 04/20 — loss: 0.6819  acc: 0.6029\n",
      "22:20:14 | INFO     | [Baseline] Epoch 05/20 — loss: 0.6618  acc: 0.6985\n",
      "22:20:44 | INFO     | [Baseline] Epoch 06/20 — loss: 0.6340  acc: 0.7206\n",
      "22:21:16 | INFO     | [Baseline] Epoch 07/20 — loss: 0.5776  acc: 0.7279\n",
      "22:21:51 | INFO     | [Baseline] Epoch 08/20 — loss: 0.5757  acc: 0.7059\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 214\u001b[0m\n\u001b[0;32m    211\u001b[0m baseline_optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(baseline_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m    212\u001b[0m num_epochs_baseline \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m--> 214\u001b[0m bl_losses, bl_accs, bl_best_epoch, bl_test_acc \u001b[38;5;241m=\u001b[39m train_and_evaluate(\n\u001b[0;32m    215\u001b[0m     baseline_model,\n\u001b[0;32m    216\u001b[0m     train_loader,\n\u001b[0;32m    217\u001b[0m     test_loader,\n\u001b[0;32m    218\u001b[0m     baseline_criterion,\n\u001b[0;32m    219\u001b[0m     baseline_optimizer,\n\u001b[0;32m    220\u001b[0m     device,\n\u001b[0;32m    221\u001b[0m     num_epochs_baseline,\n\u001b[0;32m    222\u001b[0m     prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m )\n\u001b[0;32m    225\u001b[0m plot_learning_curve(bl_accs, bl_losses, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline learning curve\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# 6. Optuna hyper-parameter tuning (5-fold CV)\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 157\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, train_loader, test_loader, criterion, optimizer, device, num_epochs, prefix)\u001b[0m\n\u001b[0;32m    154\u001b[0m train_losses, train_accs \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m--> 157\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m train_one_epoch(model, train_loader, criterion, optimizer, device)\n\u001b[0;32m    158\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m    159\u001b[0m     train_accs\u001b[38;5;241m.\u001b[39mappend(acc)\n",
      "Cell \u001b[1;32mIn[8], line 80\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, loader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     77\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     78\u001b[0m running_loss, correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     81\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     83\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    739\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\datasets\\folder.py:245\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[1;32m--> 245\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader(path)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    247\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\datasets\\folder.py:284\u001b[0m, in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pil_loader(path)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\datasets\\folder.py:264\u001b[0m, in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    263\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(f)\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:995\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    993\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m--> 995\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m    997\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\ImageFile.py:293\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(b)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CNN classifier with baseline training and Optuna hyper-parameter search.\n",
    "Plots are now saved after *every* Optuna trial.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from support import load_dataset           # ← your helper that returns (train_dataset, test_dataset)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 0. Logging configuration\n",
    "# ------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=os.getenv(\"LOGLEVEL\", \"INFO\").upper(),\n",
    "    format=\"%(asctime)s | %(levelname)-8s | %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    force=True,              # override any previous basicConfig\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.WARNING)\n",
    "\n",
    "# NEW ───────────────────────────────────────────────────────────────\n",
    "PLOTS_DIR = \"plots\"\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)      # ensure folder exists\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Reproducibility utilities\n",
    "# ------------------------------------------------------------------\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"      # harmless everywhere\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 18) -> None:\n",
    "    \"\"\"Seed Python, NumPy, PyTorch (CPU & CUDA) for deterministic runs.\"\"\"\n",
    "    logger.debug(f\"Setting global seed to {seed}\")\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Load datasets\n",
    "# ------------------------------------------------------------------\n",
    "logger.info(\"Loading datasets …\")\n",
    "train_dataset, test_dataset = load_dataset()\n",
    "logger.info(f\"Dataset sizes — train: {len(train_dataset)}  |  test: {len(test_dataset)}\")\n",
    "\n",
    "# Default DataLoaders (will be overridden by trial-specific batch sizes)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=16, shuffle=False)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Training / evaluation helpers\n",
    "# ------------------------------------------------------------------\n",
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Runs a single epoch and returns (loss, accuracy).\"\"\"\n",
    "    model.train()\n",
    "    running_loss, correct = 0.0, 0\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc  = correct / len(loader.dataset)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate(model: nn.Module, loader: DataLoader, device: torch.device) -> float:\n",
    "    \"\"\"Returns accuracy (0–1) on `loader`.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def plot_learning_curve(\n",
    "    train_accs: List[float],\n",
    "    train_losses: List[float],\n",
    "    title: str,\n",
    ") -> None:\n",
    "    \"\"\"Quick Matplotlib learning curve with best-epoch highlight.\"\"\"\n",
    "    epochs = range(1, len(train_accs) + 1)\n",
    "    best_epoch = int(np.argmax(train_accs))\n",
    "    best_acc   = train_accs[best_epoch]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(epochs, train_accs,   label=\"Train accuracy\")\n",
    "    plt.plot(epochs, train_losses, label=\"Train loss\")\n",
    "    plt.scatter(\n",
    "        best_epoch + 1,\n",
    "        best_acc,\n",
    "        c=\"red\",\n",
    "        s=80,\n",
    "        label=f\"Best acc: {best_acc:.3f} (epoch {best_epoch+1})\",\n",
    "    )\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_and_evaluate(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    test_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    num_epochs: int,\n",
    "    prefix: str,\n",
    ") -> Tuple[List[float], List[float], int, float]:\n",
    "    \"\"\"\n",
    "    Train `model` for `num_epochs` and evaluate on `test_loader`.\n",
    "    Returns (train_losses, train_accs, best_epoch, test_acc).\n",
    "    \"\"\"\n",
    "    logger.info(f\"[{prefix}] ➜ Starting training for {num_epochs} epochs\")\n",
    "    train_losses, train_accs = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        loss, acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        train_losses.append(loss)\n",
    "        train_accs.append(acc)\n",
    "        logger.info(f\"[{prefix}] Epoch {epoch+1:02}/{num_epochs} — loss: {loss:.4f}  acc: {acc:.4f}\")\n",
    "\n",
    "    best_epoch = int(np.argmax(train_accs))\n",
    "    best_acc   = train_accs[best_epoch]\n",
    "    logger.info(f\"[{prefix}] Best training acc: {best_acc:.4f} (epoch {best_epoch+1})\")\n",
    "\n",
    "    test_acc = evaluate(model, test_loader, device)\n",
    "    logger.info(f\"[{prefix}] Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    return train_losses, train_accs, best_epoch, test_acc\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. CNN architecture\n",
    "# ------------------------------------------------------------------\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_filters: int = 16, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, num_filters, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(num_filters, num_filters * 2, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        # Infer flattened size dynamically (expects 3×60×30 inputs)\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 3, 60, 30)\n",
    "            flat_features = self.features(dummy).view(1, -1).shape[1]\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flat_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. Baseline training\n",
    "# ------------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "baseline_model     = CNN(num_filters=16, dropout=0.5).to(device)\n",
    "baseline_criterion = nn.CrossEntropyLoss()\n",
    "baseline_optimizer = optim.Adam(baseline_model.parameters(), lr=1e-3)\n",
    "num_epochs_baseline = 10\n",
    "\n",
    "bl_losses, bl_accs, bl_best_epoch, bl_test_acc = train_and_evaluate(\n",
    "    baseline_model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    baseline_criterion,\n",
    "    baseline_optimizer,\n",
    "    device,\n",
    "    num_epochs_baseline,\n",
    "    prefix=\"Baseline\",\n",
    ")\n",
    "\n",
    "plot_learning_curve(bl_accs, bl_losses, \"Baseline learning curve\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. Optuna hyper-parameter tuning (5-fold CV)\n",
    "# ------------------------------------------------------------------\n",
    "logger.info(\"Starting Optuna hyper-parameter search …\")\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    # Suggest parameters\n",
    "    lr          = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    dropout     = trial.suggest_float(\"dropout\", 0.1, 0.7)\n",
    "    optimizer   = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"])\n",
    "    batch_size  = trial.suggest_categorical(\"batch_size\", [16, 32])\n",
    "    num_filters = trial.suggest_int(\"num_filters\", 16, 64, step=16)\n",
    "\n",
    "    logger.debug(\n",
    "        f\"[Trial {trial.number}] lr={lr:.2e}, dropout={dropout:.2f}, \"\n",
    "        f\"optimizer={optimizer}, batch={batch_size}, filters={num_filters}\"\n",
    "    )\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=18)\n",
    "    fold_accs = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(range(len(train_dataset))), 1):\n",
    "        train_subset = Subset(train_dataset, train_idx)\n",
    "        val_subset   = Subset(train_dataset, val_idx)\n",
    "\n",
    "        train_loader_cv = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader_cv   = DataLoader(val_subset,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model_cv = CNN(num_filters=num_filters, dropout=dropout).to(device)\n",
    "        criterion_cv = nn.CrossEntropyLoss()\n",
    "        optim_cls = optim.Adam if optimizer == \"Adam\" else optim.SGD\n",
    "        optimizer_cv = optim_cls(model_cv.parameters(), lr=lr)\n",
    "\n",
    "        for _ in range(5):  # few epochs for CV\n",
    "            train_one_epoch(model_cv, train_loader_cv, criterion_cv, optimizer_cv, device)\n",
    "\n",
    "        val_acc = evaluate(model_cv, val_loader_cv, device)\n",
    "        fold_accs.append(val_acc)\n",
    "        logger.debug(f\"[Trial {trial.number}] fold {fold}: val_acc={val_acc:.4f}\")\n",
    "\n",
    "    mean_acc = float(np.mean(fold_accs))\n",
    "    logger.debug(f\"[Trial {trial.number}] mean 5-fold acc: {mean_acc:.4f}\")\n",
    "    return mean_acc\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 7. Validation-curve helpers + per-trial callbacks  ← NEW\n",
    "# ------------------------------------------------------------------\n",
    "def save_study_progress_plot(study: optuna.Study, title: str, filepath: str) -> None:\n",
    "    \"\"\"Draw current validation curve for `study` and write to `filepath`.\"\"\"\n",
    "    trials = study.trials\n",
    "    xs = [t.number for t in trials]\n",
    "    ys = [t.value for t in trials]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(xs, ys, marker=\"o\")\n",
    "    best = study.best_trial\n",
    "    plt.scatter(best.number, best.value, c=\"red\", s=100,\n",
    "                label=f\"Best (trial {best.number})\")\n",
    "    plt.xlabel(\"Trial #\")\n",
    "    plt.ylabel(\"Mean 5-fold CV accuracy\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filepath)\n",
    "    plt.close()\n",
    "    logger.debug(f\"Saved plot ➜ {filepath}\")\n",
    "\n",
    "def make_progress_callback(prefix: str):\n",
    "    \"\"\"Factory returning a callback that saves a plot after each trial.\"\"\"\n",
    "    def _callback(study: optuna.Study, trial: optuna.trial.FrozenTrial):\n",
    "        fname = f\"{prefix}_progress_trial_{trial.number:03}.png\"\n",
    "        fpath = os.path.join(PLOTS_DIR, fname)\n",
    "        save_study_progress_plot(\n",
    "            study,\n",
    "            f\"{prefix} validation curve (up to trial {trial.number})\",\n",
    "            fpath,\n",
    "        )\n",
    "    return _callback\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 8. Random-search study ▸ 40 trials\n",
    "# ------------------------------------------------------------------\n",
    "random_study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.RandomSampler(seed=18),\n",
    ")\n",
    "random_study.optimize(\n",
    "    objective,\n",
    "    n_trials=40,\n",
    "    show_progress_bar=True,\n",
    "    callbacks=[make_progress_callback(\"random\")],   # ← NEW\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 9. TPE study ▸ 40 trials\n",
    "# ------------------------------------------------------------------\n",
    "tpe_study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=18),\n",
    ")\n",
    "tpe_study.optimize(\n",
    "    objective,\n",
    "    n_trials=40,\n",
    "    show_progress_bar=True,\n",
    "    callbacks=[make_progress_callback(\"tpe\")],      # ← NEW\n",
    ")\n",
    "\n",
    "logger.info(f\"Random-search best params: {random_study.best_params}\")\n",
    "logger.info(f\"Random-search best CV acc: {random_study.best_value:.4f}\")\n",
    "logger.info(f\"TPE best params         : {tpe_study.best_params}\")\n",
    "logger.info(f\"TPE best CV acc         : {tpe_study.best_value:.4f}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 10. Final “static” validation curves (complete)\n",
    "# ------------------------------------------------------------------\n",
    "def _plot_val_curve(study: optuna.Study, title: str) -> None:\n",
    "    trials = study.trials\n",
    "    xs = [t.number for t in trials]\n",
    "    ys = [t.value for t in trials]\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(xs, ys, marker=\"o\")\n",
    "    best = study.best_trial\n",
    "    plt.scatter(best.number, best.value, c=\"red\", s=100,\n",
    "                label=f\"Best (trial {best.number})\")\n",
    "    plt.xlabel(\"Trial #\")\n",
    "    plt.ylabel(\"Mean 5-fold CV accuracy\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "_plot_val_curve(random_study, \"Random search validation curve (40 trials)\")\n",
    "_plot_val_curve(tpe_study,    \"TPE validation curve (40 trials)\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 11. Retrain final model with TPE best hyper-parameters\n",
    "# ------------------------------------------------------------------\n",
    "logger.info(\"Retraining full model with TPE-selected parameters …\")\n",
    "best_tpe = tpe_study.best_params\n",
    "final_model_tpe = CNN(\n",
    "    num_filters=best_tpe[\"num_filters\"],\n",
    "    dropout=best_tpe[\"dropout\"],\n",
    ").to(device)\n",
    "\n",
    "criterion_tpe = nn.CrossEntropyLoss()\n",
    "optim_cls_tpe = optim.Adam if best_tpe[\"optimizer\"] == \"Adam\" else optim.SGD\n",
    "optimizer_tpe = optim_cls_tpe(final_model_tpe.parameters(), lr=best_tpe[\"lr\"])\n",
    "\n",
    "full_train_loader_tpe = DataLoader(train_dataset,\n",
    "                                   batch_size=best_tpe[\"batch_size\"],\n",
    "                                   shuffle=True)\n",
    "\n",
    "tpe_losses, tpe_accs, tpe_best_epoch, tpe_test_acc = train_and_evaluate(\n",
    "    final_model_tpe,\n",
    "    full_train_loader_tpe,\n",
    "    test_loader,\n",
    "    criterion_tpe,\n",
    "    optimizer_tpe,\n",
    "    device,\n",
    "    num_epochs=20,\n",
    "    prefix=\"TPE-final\",\n",
    ")\n",
    "\n",
    "plot_learning_curve(tpe_accs, tpe_losses, \"Learning curve — final TPE model\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 12. Retrain final model with Random-search best hyper-parameters\n",
    "# ------------------------------------------------------------------\n",
    "logger.info(\"Retraining full model with Random-search-selected parameters …\")\n",
    "best_rs = random_study.best_params\n",
    "final_model_rs = CNN(\n",
    "    num_filters=best_rs[\"num_filters\"],\n",
    "    dropout=best_rs[\"dropout\"],\n",
    ").to(device)\n",
    "\n",
    "criterion_rs = nn.CrossEntropyLoss()\n",
    "optim_cls_rs = optim.Adam if best_rs[\"optimizer\"] == \"Adam\" else optim.SGD\n",
    "optimizer_rs = optim_cls_rs(final_model_rs.parameters(), lr=best_rs[\"lr\"])\n",
    "\n",
    "full_train_loader_rs = DataLoader(train_dataset,\n",
    "                                  batch_size=best_rs[\"batch_size\"],\n",
    "                                  shuffle=True)\n",
    "\n",
    "rs_losses, rs_accs, rs_best_epoch, rs_test_acc = train_and_evaluate(\n",
    "    final_model_rs,\n",
    "    full_train_loader_rs,\n",
    "    test_loader,\n",
    "    criterion_rs,\n",
    "    optimizer_rs,\n",
    "    device,\n",
    "    num_epochs=20,\n",
    "    prefix=\"RS-final\",\n",
    ")\n",
    "\n",
    "plot_learning_curve(rs_accs, rs_losses, \"Learning curve — final Random-search model\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 13. Persist models\n",
    "# ------------------------------------------------------------------\n",
    "logger.info(\"Saving final model weights …\")\n",
    "torch.save(final_model_tpe.state_dict(), \"cnn_final_tpe_5foldcv.pth\")\n",
    "torch.save(final_model_rs.state_dict(),  \"cnn_final_rs_5foldcv.pth\")\n",
    "logger.info(\"Done! 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d386162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01 | loss=0.7053 acc=0.4118\n",
      "[Baseline] Epoch 02 | loss=0.6930 acc=0.5147\n",
      "[Baseline] Epoch 03 | loss=0.6910 acc=0.5441\n",
      "[Baseline] Epoch 04 | loss=0.6819 acc=0.6029\n",
      "[Baseline] Epoch 05 | loss=0.6618 acc=0.6985\n",
      "[Baseline] Epoch 06 | loss=0.6340 acc=0.7206\n",
      "[Baseline] Epoch 07 | loss=0.5776 acc=0.7279\n",
      "[Baseline] Epoch 08 | loss=0.5757 acc=0.7059\n",
      "[Baseline] Epoch 09 | loss=0.6240 acc=0.6618\n",
      "[Baseline] Epoch 10 | loss=0.5308 acc=0.7574\n",
      "[Baseline] Best train acc 0.7574 @ epoch 10\n",
      "[Baseline] Final test acc 0.5588\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:09:18,791] A new study created in memory with name: no-name-8d252254-e7eb-42e0-a8d1-7bb13f225867\n",
      "[I 2025-06-03 23:42:45,092] Trial 0 finished with value: 0.8894179894179894 and parameters: {'lr': 0.0008935579543655974, 'dropout': 0.4032720242409057, 'optimizer': 'Adam', 'batch_size': 16, 'num_filters': 48}. Best is trial 0 with value: 0.8894179894179894.\n",
      "[I 2025-06-04 00:15:58,693] Trial 1 finished with value: 0.40476190476190477 and parameters: {'lr': 0.009197850467534774, 'dropout': 0.2541810535622981, 'optimizer': 'SGD', 'batch_size': 16, 'num_filters': 16}. Best is trial 0 with value: 0.8894179894179894.\n",
      "[I 2025-06-04 00:49:55,277] Trial 2 finished with value: 0.44179894179894175 and parameters: {'lr': 2.1617695339723554e-05, 'dropout': 0.27863424511351587, 'optimizer': 'SGD', 'batch_size': 32, 'num_filters': 48}. Best is trial 0 with value: 0.8894179894179894.\n",
      "[I 2025-06-04 01:24:46,319] Trial 3 finished with value: 0.7936507936507936 and parameters: {'lr': 0.0001140715666811961, 'dropout': 0.5739763286951839, 'optimizer': 'Adam', 'batch_size': 16, 'num_filters': 48}. Best is trial 0 with value: 0.8894179894179894.\n",
      "[I 2025-06-04 01:59:23,724] Trial 4 finished with value: 0.4936507936507937 and parameters: {'lr': 4.304632811886419e-05, 'dropout': 0.5845157943096871, 'optimizer': 'Adam', 'batch_size': 32, 'num_filters': 48}. Best is trial 0 with value: 0.8894179894179894.\n",
      "[I 2025-06-04 02:34:18,362] Trial 5 finished with value: 0.5595238095238095 and parameters: {'lr': 3.7586528393144894e-05, 'dropout': 0.5285540444179843, 'optimizer': 'Adam', 'batch_size': 16, 'num_filters': 48}. Best is trial 0 with value: 0.8894179894179894.\n",
      "[I 2025-06-04 03:08:30,874] Trial 6 finished with value: 0.501058201058201 and parameters: {'lr': 0.0004017701166362089, 'dropout': 0.14748083037004955, 'optimizer': 'SGD', 'batch_size': 16, 'num_filters': 16}. Best is trial 0 with value: 0.8894179894179894.\n",
      "[I 2025-06-04 03:43:05,935] Trial 7 finished with value: 0.464021164021164 and parameters: {'lr': 1.1191861733928418e-05, 'dropout': 0.30497647137834466, 'optimizer': 'Adam', 'batch_size': 32, 'num_filters': 16}. Best is trial 0 with value: 0.8894179894179894.\n",
      "[I 2025-06-04 04:15:20,395] Trial 8 finished with value: 0.8899470899470898 and parameters: {'lr': 0.002263123538794808, 'dropout': 0.5112181712874466, 'optimizer': 'Adam', 'batch_size': 32, 'num_filters': 32}. Best is trial 8 with value: 0.8899470899470898.\n",
      "[I 2025-06-04 04:46:22,932] Trial 9 finished with value: 0.5751322751322752 and parameters: {'lr': 0.00919091449220507, 'dropout': 0.39774723393251554, 'optimizer': 'Adam', 'batch_size': 32, 'num_filters': 48}. Best is trial 8 with value: 0.8899470899470898.\n",
      "[I 2025-06-04 05:17:33,213] Trial 10 finished with value: 0.9037037037037038 and parameters: {'lr': 0.0009527219844060178, 'dropout': 0.12122133156417805, 'optimizer': 'Adam', 'batch_size': 16, 'num_filters': 32}. Best is trial 10 with value: 0.9037037037037038.\n",
      "[I 2025-06-04 05:49:12,886] Trial 11 finished with value: 0.785978835978836 and parameters: {'lr': 9.516802197640578e-05, 'dropout': 0.1888107042447095, 'optimizer': 'Adam', 'batch_size': 16, 'num_filters': 48}. Best is trial 10 with value: 0.9037037037037038.\n",
      "[I 2025-06-04 06:20:49,200] Trial 12 finished with value: 0.40476190476190477 and parameters: {'lr': 1.5899408160582198e-05, 'dropout': 0.5723620078767301, 'optimizer': 'SGD', 'batch_size': 32, 'num_filters': 32}. Best is trial 10 with value: 0.9037037037037038.\n",
      "[I 2025-06-04 06:52:43,830] Trial 13 finished with value: 0.7521164021164022 and parameters: {'lr': 0.00011317754509640176, 'dropout': 0.12850305703763282, 'optimizer': 'Adam', 'batch_size': 32, 'num_filters': 64}. Best is trial 10 with value: 0.9037037037037038.\n",
      "[I 2025-06-04 07:24:39,734] Trial 14 finished with value: 0.8526455026455025 and parameters: {'lr': 0.0025739654259925144, 'dropout': 0.21488967291975586, 'optimizer': 'Adam', 'batch_size': 32, 'num_filters': 32}. Best is trial 10 with value: 0.9037037037037038.\n",
      "[I 2025-06-04 08:00:02,790] Trial 15 finished with value: 0.4492063492063492 and parameters: {'lr': 0.00041498776937014736, 'dropout': 0.6514677039760887, 'optimizer': 'SGD', 'batch_size': 16, 'num_filters': 64}. Best is trial 10 with value: 0.9037037037037038.\n",
      "[I 2025-06-04 08:41:16,334] Trial 16 finished with value: 0.815873015873016 and parameters: {'lr': 0.00042000563658457416, 'dropout': 0.2748657998975828, 'optimizer': 'Adam', 'batch_size': 32, 'num_filters': 32}. Best is trial 10 with value: 0.9037037037037038.\n",
      "[I 2025-06-04 09:17:27,885] Trial 17 finished with value: 0.7648148148148148 and parameters: {'lr': 0.0005650164946106076, 'dropout': 0.11089843379562994, 'optimizer': 'Adam', 'batch_size': 32, 'num_filters': 16}. Best is trial 10 with value: 0.9037037037037038.\n",
      "[I 2025-06-04 09:52:44,779] Trial 18 finished with value: 0.5878306878306877 and parameters: {'lr': 0.0001528203825706993, 'dropout': 0.4293532450348009, 'optimizer': 'SGD', 'batch_size': 16, 'num_filters': 32}. Best is trial 10 with value: 0.9037037037037038.\n",
      "[I 2025-06-04 10:28:10,046] Trial 19 finished with value: 0.6677248677248678 and parameters: {'lr': 6.172725281296808e-05, 'dropout': 0.12427959035810313, 'optimizer': 'Adam', 'batch_size': 32, 'num_filters': 64}. Best is trial 10 with value: 0.9037037037037038.\n",
      "[I 2025-06-04 11:16:28,780] Trial 20 finished with value: 0.8825396825396826 and parameters: {'lr': 0.0003884504180242845, 'dropout': 0.6075439946585228, 'optimizer': 'Adam', 'batch_size': 32, 'num_filters': 64}. Best is trial 10 with value: 0.9037037037037038.\n",
      "[I 2025-06-04 12:00:39,593] Trial 21 finished with value: 0.4544973544973545 and parameters: {'lr': 0.0003146958388179649, 'dropout': 0.35944814123061064, 'optimizer': 'SGD', 'batch_size': 16, 'num_filters': 64}. Best is trial 10 with value: 0.9037037037037038.\n",
      "[I 2025-06-04 12:44:06,407] Trial 22 finished with value: 0.6047619047619047 and parameters: {'lr': 0.00010443269455256077, 'dropout': 0.5879304030325971, 'optimizer': 'Adam', 'batch_size': 32, 'num_filters': 48}. Best is trial 10 with value: 0.9037037037037038.\n",
      "[I 2025-06-04 13:51:45,324] Trial 23 finished with value: 0.5656084656084656 and parameters: {'lr': 0.00015051382279390832, 'dropout': 0.2766991264011857, 'optimizer': 'SGD', 'batch_size': 32, 'num_filters': 64}. Best is trial 10 with value: 0.9037037037037038.\n",
      "[W 2025-06-04 13:53:47,054] Trial 24 failed with parameters: {'lr': 0.004219725321287173, 'dropout': 0.667321755425072, 'optimizer': 'SGD', 'batch_size': 32, 'num_filters': 32} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\flori\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_12780\\3913111963.py\", line 205, in objective\n",
      "    train_one_epoch(model, tr_loader, crit, opt, DEVICE)\n",
      "  File \"C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_12780\\3913111963.py\", line 71, in train_one_epoch\n",
      "    for X, y in loader:\n",
      "                ^^^^^^\n",
      "  File \"C:\\Users\\flori\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py\", line 733, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\flori\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py\", line 789, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\flori\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 50, in fetch\n",
      "    data = self.dataset.__getitems__(possibly_batched_index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\flori\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataset.py\", line 416, in __getitems__\n",
      "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
      "            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\flori\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\datasets\\folder.py\", line 245, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\flori\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\datasets\\folder.py\", line 284, in default_loader\n",
      "    return pil_loader(path)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\flori\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\datasets\\folder.py\", line 264, in pil_loader\n",
      "    return img.convert(\"RGB\")\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\Image.py\", line 995, in convert\n",
      "    self.load()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\ImageFile.py\", line 293, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-06-04 13:53:47,102] Trial 24 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 215\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# 7 .  Random search & TPE\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[0;32m    213\u001b[0m rs_study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    214\u001b[0m                                sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mRandomSampler(seed\u001b[38;5;241m=\u001b[39mSEED))\n\u001b[1;32m--> 215\u001b[0m rs_study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39mN_TRIALS_RS)\n\u001b[0;32m    217\u001b[0m tpe_study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    218\u001b[0m                                 sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39mSEED))\n\u001b[0;32m    219\u001b[0m tpe_study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39mN_TRIALS_TPE)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     _optimize(\n\u001b[0;32m    476\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    477\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    478\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    479\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    480\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    481\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    482\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    483\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    484\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    485\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[0;32m     64\u001b[0m             study,\n\u001b[0;32m     65\u001b[0m             func,\n\u001b[0;32m     66\u001b[0m             n_trials,\n\u001b[0;32m     67\u001b[0m             timeout,\n\u001b[0;32m     68\u001b[0m             catch,\n\u001b[0;32m     69\u001b[0m             callbacks,\n\u001b[0;32m     70\u001b[0m             gc_after_trial,\n\u001b[0;32m     71\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     73\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     74\u001b[0m         )\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[1], line 205\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m    200\u001b[0m     opt   \u001b[38;5;241m=\u001b[39m (optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m    201\u001b[0m              \u001b[38;5;28;01mif\u001b[39;00m optimizerNm\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m    202\u001b[0m              optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr))\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS_CV):\n\u001b[1;32m--> 205\u001b[0m         train_one_epoch(model, tr_loader, crit, opt, DEVICE)\n\u001b[0;32m    206\u001b[0m     fold_accs\u001b[38;5;241m.\u001b[39mappend(evaluate(model, val_loader, DEVICE))\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(fold_accs))\n",
      "Cell \u001b[1;32mIn[1], line 71\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, loader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_one_epoch\u001b[39m(model, loader, criterion, optimizer, device):\n\u001b[0;32m     70\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(); running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m; correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     72\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     73\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    739\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataset.py:416\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\datasets\\folder.py:245\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[1;32m--> 245\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader(path)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    247\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\datasets\\folder.py:284\u001b[0m, in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pil_loader(path)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\datasets\\folder.py:264\u001b[0m, in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    263\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(f)\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:995\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    993\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m--> 995\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m    997\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\ImageFile.py:293\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(b)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0 . User-tunable parameters\n",
    "# ============================================================\n",
    "# Reproducibility\n",
    "SEED = 18                        # random-seed for Python / NumPy / PyTorch\n",
    "\n",
    "# Data & model\n",
    "INPUT_SIZE        = (3, 60, 30)  # C × H × W –​ used for dummy tensor\n",
    "BASE_BATCH_SIZE   = 16           # baseline training\n",
    "NUM_EPOCHS_BASE   = 10           # baseline\n",
    "KFOLDS            = 5            # CV folds\n",
    "NUM_EPOCHS_CV     = 20            # per-fold epoch count during Optuna trials\n",
    "NUM_EPOCHS_FINAL  = 20           # retrain with best hyper-params\n",
    "\n",
    "# Hyper-parameter search\n",
    "N_TRIALS_RS       = 30           # RandomSampler trials\n",
    "N_TRIALS_TPE      = 30           # TPESampler trials\n",
    "HYPERPARAMS_SPACE = {\n",
    "    \"lr\":         (1e-5, 1e-2, \"log\"),                # (low, high, scale)\n",
    "    \"dropout\":    (0.1, 0.7),\n",
    "    \"optimizer\":  [\"Adam\", \"SGD\"],\n",
    "    \"batch_size\": [16, 32],\n",
    "    \"num_filters\": (16, 64, 16)                       # (low, high, step)\n",
    "}\n",
    "\n",
    "# Plotting\n",
    "PLOT_DIR          = \"plots\"       # folder where every figure is stored\n",
    "PLOT_FORMAT       = \"png\"         # png / pdf / svg …\n",
    "SHOW_FIGS_ONLINE  = True          # set False if running on headless node\n",
    "\n",
    "# ============================================================\n",
    "# 1 . Imports & housekeeping\n",
    "# ============================================================\n",
    "import os, random, numpy as np\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from support import load_dataset              # <- your own helper\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "Path(PLOT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1.a  Reproducibility helper\n",
    "# ------------------------------------------------------------\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark     = False\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# ============================================================\n",
    "# 2 . Load dataset & create baseline loaders\n",
    "# ============================================================\n",
    "train_dataset, test_dataset = load_dataset()\n",
    "train_loader = DataLoader(train_dataset, batch_size=BASE_BATCH_SIZE, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BASE_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ============================================================\n",
    "# 3 .  Training utilities\n",
    "# ============================================================\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train(); running_loss = 0.0; correct = 0\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss   = criterion(logits, y)\n",
    "        loss.backward(); optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "        correct      += (logits.argmax(1) == y).sum().item()\n",
    "\n",
    "    n = len(loader.dataset)\n",
    "    return running_loss / n, correct / n\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval(); correct = 0\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        correct += (model(X).argmax(1) == y).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "def save_current_fig(filename: str):\n",
    "    \"\"\"Helper to save *and optionally show* the active Matplotlib figure.\"\"\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(PLOT_DIR, filename), format=PLOT_FORMAT, dpi=300)\n",
    "    if SHOW_FIGS_ONLINE:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "def plot_learning_curve(accs, losses, title, fname):\n",
    "    epochs      = range(1, len(accs) + 1)\n",
    "    best_idx    = int(np.argmax(accs))\n",
    "    best_acc    = accs[best_idx]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(epochs, accs,   label=\"Train Accuracy\")\n",
    "    plt.plot(epochs, losses, label=\"Train Loss\")\n",
    "    plt.scatter(best_idx+1, best_acc, color=\"red\", s=80,\n",
    "                label=f\"Best (E{best_idx+1}, {best_acc:.3f})\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Value\"); plt.title(title); plt.legend()\n",
    "    save_current_fig(fname)\n",
    "\n",
    "def train_and_evaluate(model, train_loader, test_loader,\n",
    "                       criterion, optimizer, device,\n",
    "                       num_epochs, prefix):\n",
    "    accs, losses = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        loss, acc = train_one_epoch(model, train_loader,\n",
    "                                    criterion, optimizer, device)\n",
    "        losses.append(loss); accs.append(acc)\n",
    "        print(f\"[{prefix}] Epoch {epoch+1:02d} | loss={loss:.4f} acc={acc:.4f}\")\n",
    "\n",
    "    best_idx = int(np.argmax(accs))\n",
    "    print(f\"[{prefix}] Best train acc {accs[best_idx]:.4f} @ epoch {best_idx+1}\")\n",
    "\n",
    "    test_acc = evaluate(model, test_loader, device)\n",
    "    print(f\"[{prefix}] Final test acc {test_acc:.4f}\")\n",
    "\n",
    "    return losses, accs, best_idx, test_acc\n",
    "\n",
    "# ============================================================\n",
    "# 4 .  CNN definition\n",
    "# ============================================================\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_filters: int = 16, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, num_filters, 3, padding=1),\n",
    "            nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(num_filters, num_filters*2, 3, padding=1),\n",
    "            nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        # compute flattened size dynamically\n",
    "        with torch.no_grad():\n",
    "            dummy  = torch.zeros(1, *INPUT_SIZE)\n",
    "            flat   = self.features(dummy).view(1, -1).shape[1]\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flat, 128), nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x): return self.classifier(self.features(x))\n",
    "\n",
    "# ============================================================\n",
    "# 5 .  Baseline experiment\n",
    "# ============================================================\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "baseline = CNN().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(baseline.parameters(), lr=1e-3)\n",
    "\n",
    "bl_loss, bl_acc, bl_best, bl_test = train_and_evaluate(\n",
    "    baseline, train_loader, test_loader, criterion, optimizer,\n",
    "    DEVICE, NUM_EPOCHS_BASE, prefix=\"Baseline\"\n",
    ")\n",
    "plot_learning_curve(bl_acc, bl_loss,\n",
    "                    title=\"Baseline Learning Curve\",\n",
    "                    fname=\"baseline_learning_curve.png\")\n",
    "\n",
    "# ============================================================\n",
    "# 6 .  Optuna objective\n",
    "# ============================================================\n",
    "def objective(trial):\n",
    "    lr_low, lr_high, lr_scale     = HYPERPARAMS_SPACE[\"lr\"]\n",
    "    dropout_low, dropout_high     = HYPERPARAMS_SPACE[\"dropout\"]\n",
    "    nFilt_low, nFilt_high, n_step = HYPERPARAMS_SPACE[\"num_filters\"]\n",
    "\n",
    "    lr          = trial.suggest_float(\"lr\", lr_low, lr_high, log=(lr_scale==\"log\"))\n",
    "    dropout     = trial.suggest_float(\"dropout\", dropout_low, dropout_high)\n",
    "    optimizerNm = trial.suggest_categorical(\"optimizer\", HYPERPARAMS_SPACE[\"optimizer\"])\n",
    "    batch_size  = trial.suggest_categorical(\"batch_size\", HYPERPARAMS_SPACE[\"batch_size\"])\n",
    "    num_filters = trial.suggest_int(\"num_filters\", nFilt_low, nFilt_high, step=n_step)\n",
    "\n",
    "    kf = KFold(n_splits=KFOLDS, shuffle=True, random_state=SEED)\n",
    "    fold_accs = []\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(range(len(train_dataset)))):\n",
    "        tr_loader = DataLoader(Subset(train_dataset, tr_idx),\n",
    "                               batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(Subset(train_dataset, val_idx),\n",
    "                                batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = CNN(num_filters=num_filters, dropout=dropout).to(DEVICE)\n",
    "        crit  = nn.CrossEntropyLoss()\n",
    "        opt   = (optim.Adam(model.parameters(), lr=lr)\n",
    "                 if optimizerNm==\"Adam\" else\n",
    "                 optim.SGD(model.parameters(), lr=lr))\n",
    "\n",
    "        for _ in range(NUM_EPOCHS_CV):\n",
    "            train_one_epoch(model, tr_loader, crit, opt, DEVICE)\n",
    "        fold_accs.append(evaluate(model, val_loader, DEVICE))\n",
    "\n",
    "    return float(np.mean(fold_accs))\n",
    "\n",
    "# ============================================================\n",
    "# 7 .  Random search & TPE\n",
    "# ============================================================\n",
    "rs_study = optuna.create_study(direction=\"maximize\",\n",
    "                               sampler=optuna.samplers.RandomSampler(seed=SEED))\n",
    "rs_study.optimize(objective, n_trials=N_TRIALS_RS)\n",
    "\n",
    "tpe_study = optuna.create_study(direction=\"maximize\",\n",
    "                                sampler=optuna.samplers.TPESampler(seed=SEED))\n",
    "tpe_study.optimize(objective, n_trials=N_TRIALS_TPE)\n",
    "\n",
    "print(\"\\nBest (Random):\", rs_study.best_params,\n",
    "      f\"CV Acc={rs_study.best_value:.4f}\")\n",
    "print(\"Best (TPE):   \", tpe_study.best_params,\n",
    "      f\"CV Acc={tpe_study.best_value:.4f}\")\n",
    "\n",
    "# Validation-curve helper\n",
    "def plot_validation_curve(study, title, fname):\n",
    "    nums   = [t.number for t in study.trials]\n",
    "    values = [t.value  for t in study.trials]\n",
    "    best   = study.best_trial\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(nums, values, marker=\"o\")\n",
    "    plt.scatter(best.number, best.value, s=100, c=\"red\",\n",
    "                label=f\"Best (T{best.number})\")\n",
    "    plt.xlabel(\"Trial\"); plt.ylabel(\"Mean CV Acc\"); plt.title(title)\n",
    "    plt.legend(); save_current_fig(fname)\n",
    "\n",
    "plot_validation_curve(rs_study,  \"Random Search (20 trials)\",\n",
    "                      \"rs_validation_curve.png\")\n",
    "plot_validation_curve(tpe_study, \"TPE (20 trials)\",\n",
    "                      \"tpe_validation_curve.png\")\n",
    "\n",
    "# ============================================================\n",
    "# 8 .  Retrain with best TPE hyper-params\n",
    "# ============================================================\n",
    "bp = tpe_study.best_params\n",
    "tpe_model = CNN(num_filters=bp[\"num_filters\"], dropout=bp[\"dropout\"]).to(DEVICE)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "opt  = (optim.Adam(tpe_model.parameters(), lr=bp[\"lr\"])\n",
    "        if bp[\"optimizer\"]==\"Adam\"\n",
    "        else optim.SGD(tpe_model.parameters(), lr=bp[\"lr\"]))\n",
    "loader = DataLoader(train_dataset, batch_size=bp[\"batch_size\"], shuffle=True)\n",
    "\n",
    "tpe_loss, tpe_acc, _, tpe_test = train_and_evaluate(\n",
    "    tpe_model, loader, test_loader, crit, opt, DEVICE,\n",
    "    NUM_EPOCHS_FINAL, prefix=\"TPE-final\"\n",
    ")\n",
    "plot_learning_curve(tpe_acc, tpe_loss,\n",
    "                    \"Learning Curve (TPE final)\",\n",
    "                    \"tpe_final_learning_curve.png\")\n",
    "\n",
    "# ============================================================\n",
    "# 9 .  Retrain with best Random-search hyper-params\n",
    "# ============================================================\n",
    "bp = rs_study.best_params\n",
    "rs_model = CNN(num_filters=bp[\"num_filters\"], dropout=bp[\"dropout\"]).to(DEVICE)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "opt  = (optim.Adam(rs_model.parameters(), lr=bp[\"lr\"])\n",
    "        if bp[\"optimizer\"]==\"Adam\"\n",
    "        else optim.SGD(rs_model.parameters(), lr=bp[\"lr\"]))\n",
    "loader = DataLoader(train_dataset, batch_size=bp[\"batch_size\"], shuffle=True)\n",
    "\n",
    "rs_loss, rs_acc, _, rs_test = train_and_evaluate(\n",
    "    rs_model, loader, test_loader, crit, opt, DEVICE,\n",
    "    NUM_EPOCHS_FINAL, prefix=\"RS-final\"\n",
    ")\n",
    "plot_learning_curve(rs_acc, rs_loss,\n",
    "                    \"Learning Curve (RS final)\",\n",
    "                    \"rs_final_learning_curve.png\")\n",
    "\n",
    "# ============================================================\n",
    "# 10 .  Save model weights\n",
    "# ============================================================\n",
    "torch.save(tpe_model.state_dict(), Path(\"cnn_final_tpe_5foldcv.pth\"))\n",
    "torch.save(rs_model.state_dict(),  Path(\"cnn_final_rs_5foldcv.pth\"))\n",
    "print(\"\\nAll done – plots saved to\", Path(PLOT_DIR).resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
